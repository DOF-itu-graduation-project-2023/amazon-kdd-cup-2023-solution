{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIjdpIpL6hog"
   },
   "source": [
    "# ‚öôÔ∏è Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CRxB48iDiAF_",
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:00.463172Z",
     "end_time": "2023-05-18T16:20:00.474174Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Python built-in libraries\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:00.620884Z",
     "end_time": "2023-05-18T16:20:00.627883Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import pip libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# Import torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "HGQ13SWwiHRl",
    "outputId": "d12c60ec-b6e4-4a7b-ea7d-42eb63711c87",
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:00.798570Z",
     "end_time": "2023-05-18T16:20:00.814942Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import PyG packages\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric.data as pyg_data\n",
    "from torch_geometric.typing import Adj, OptTensor\n",
    "import torch_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:00.974335Z",
     "end_time": "2023-05-18T16:20:00.987337Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYrSfhkh6nIc"
   },
   "source": [
    "# ‚öóÔ∏è Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AK8wBmby8SWt"
   },
   "source": [
    "# üì¶ Data Pipeline\n",
    "\n",
    "For data ingestion, we use PyTorch's `dataloader` and PyG's `Data` class. To learn more about the `Data` class, check out the documentation [here](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#module-torch_geometric.data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "82KWESLd-1gV",
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:01.705290Z",
     "end_time": "2023-05-18T16:20:01.708292Z"
    }
   },
   "outputs": [],
   "source": [
    "class GraphDataset(pyg_data.InMemoryDataset):\n",
    "    def __init__(self, root, file_name, transform=None, pre_transform=None):\n",
    "        self.file_name = file_name\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [f'{self.file_name}.txt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f'{self.file_name}.pt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        data_list = []\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        for session in sessions:\n",
    "            codes, uniques = pd.factorize(session)\n",
    "            senders, receivers = codes[:-1], codes[1:]\n",
    "\n",
    "            # Build Data instance\n",
    "            edge_index = torch.tensor([senders, receivers], dtype=torch.long)\n",
    "            #x = torch.tensor(uniques, dtype=torch.long)\n",
    "            x_new = torch.zeros((len(uniques), 100))\n",
    "\n",
    "            item_counter = 0\n",
    "            for item in uniques:\n",
    "                x_new[item_counter] = torch.tensor(embeddings[item])\n",
    "                item_counter += 1\n",
    "\n",
    "            #y = torch.tensor([y], dtype=torch.long)\n",
    "\n",
    "            data_list.append(pyg_data.Data(x=x_new, edge_index=edge_index))\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD9bwJaUCOge"
   },
   "source": [
    "# üîÆ Model Design\n",
    "\n",
    "Our gated session graph layer has two main parts: (1) message propagation to create an adjacency matrix (`self.propagate`) and (2) the GRU cell (`self.gru`). We will put these inside the `forward()` function.\n",
    "\n",
    "We only use one layer for our `GatedSessionGraphConv` implementation for simplicity. Also, our sessions have average length < 5, so we do not need a large receptive field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7K3HWrcwqp0Z",
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:02.233366Z",
     "end_time": "2023-05-18T16:20:02.239383Z"
    }
   },
   "outputs": [],
   "source": [
    "class GatedSessionGraphConv(pyg.nn.conv.MessagePassing):\n",
    "    def __init__(self, out_channels, aggr: str = 'add', **kwargs):\n",
    "        super().__init__(aggr=aggr, **kwargs)\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.gru = torch.nn.GRUCell(out_channels, out_channels, bias=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        m = self.propagate(edge_index, x=x, size=None)\n",
    "        x = self.gru(m, x)\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t, x):\n",
    "        return matmul(adj_t, x, reduce=self.aggr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "TNsAHq8PCN3k",
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:02.578956Z",
     "end_time": "2023-05-18T16:20:02.609952Z"
    }
   },
   "outputs": [],
   "source": [
    "class SRGNN(nn.Module):\n",
    "    def __init__(self, hidden_size, n_items):\n",
    "        super(SRGNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_items = n_items\n",
    "\n",
    "        self.gated = GatedSessionGraphConv(self.hidden_size)\n",
    "\n",
    "        self.q = nn.Linear(self.hidden_size, 1)\n",
    "        self.W_1 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.W_2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.W_3 = nn.Linear(2 * self.hidden_size, self.hidden_size, bias=False)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch_map = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # (0)\n",
    "        #embedding = self.embedding(x).squeeze()\n",
    "\n",
    "        # (1)-(5)\n",
    "        v_i = self.gated(x, edge_index)\n",
    "\n",
    "        # Divide nodes by session\n",
    "        # For the detailed explanation of what is happening below, please refer\n",
    "        # to the Medium blog post.\n",
    "        sections = list(torch.bincount(batch_map).cpu())\n",
    "        v_i_split = torch.split(v_i, sections)\n",
    "\n",
    "        v_n, v_n_repeat = [], []\n",
    "        for session in v_i_split:\n",
    "            v_n.append(session[-1])\n",
    "            v_n_repeat.append(\n",
    "                session[-1].view(1, -1).repeat(session.shape[0], 1))\n",
    "        v_n, v_n_repeat = torch.stack(v_n), torch.cat(v_n_repeat, dim=0)\n",
    "\n",
    "        q1 = self.W_1(v_n_repeat)\n",
    "        q2 = self.W_2(v_i)\n",
    "\n",
    "        # (6)\n",
    "        alpha = self.q(F.sigmoid(q1 + q2))\n",
    "        s_g_split = torch.split(alpha * v_i, sections)\n",
    "\n",
    "        s_g = []\n",
    "        for session in s_g_split:\n",
    "            s_g_session = torch.sum(session, dim=0)\n",
    "            s_g.append(s_g_session)\n",
    "        s_g = torch.stack(s_g)\n",
    "\n",
    "        # (7)\n",
    "        s_l = v_n\n",
    "        s_h = self.W_3(torch.cat([s_l, s_g], dim=-1))\n",
    "        #print(\"SH: \")\n",
    "        #print(s_h.shape)\n",
    "        #print(s_h)\n",
    "\n",
    "\n",
    "        return s_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qd0wGgxOAIoJ"
   },
   "source": [
    "# üöÇ Model Training\n",
    "\n",
    "We can now start model training. The training pipeline code below was originally taken from the 2021 Fall CS224W Colab assignments and then modified to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Define the hyperparameters.\n",
    "# Code taken from 2021 Fall CS224W Colab assignments.\n",
    "args = {\n",
    "    'batch_size': 100,\n",
    "    'hidden_dim': 100,\n",
    "    'epochs': 1,\n",
    "    'l2_penalty': 0.00001,\n",
    "    'weight_decay': 0.1,\n",
    "    'step': 30,\n",
    "    'lr': 0.001,\n",
    "    'num_items': 466868}\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "\n",
    "args = objectview(args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:03.289715Z",
     "end_time": "2023-05-18T16:20:03.299714Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def test(loader, test_model,num_of_sessions, save_model_preds=False):\n",
    "    test_model.eval()\n",
    "\n",
    "    preds_all = torch.zeros(num_of_sessions, 100)\n",
    "    i = 0\n",
    "\n",
    "    for _, data in enumerate(tqdm(loader)):\n",
    "        data\n",
    "        with torch.no_grad():\n",
    "            # max(dim=1) returns values, indices tuple; only need indices\n",
    "            preds = test_model(data)\n",
    "            preds_all[i*args.batch_size:(i+1)*args.batch_size,:] = preds\n",
    "            i += 1\n",
    "\n",
    "    if save_model_preds:\n",
    "        np_preds = preds_all.cpu().detach().numpy()\n",
    "        return np_preds\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:54.731217Z",
     "end_time": "2023-05-18T16:20:54.743413Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 81/890 [00:01<00:19, 41.54it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (76) must match the existing size (100) at non-singleton dimension 0.  Target sizes: [76, 100].  Tensor sizes: [100, 100]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 24\u001B[0m\n\u001B[0;32m     21\u001B[0m model \u001B[38;5;241m=\u001B[39m SRGNN(args\u001B[38;5;241m.\u001B[39mhidden_dim, args\u001B[38;5;241m.\u001B[39mnum_items)\n\u001B[0;32m     22\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(torch\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../model/\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(model_name)))\n\u001B[1;32m---> 24\u001B[0m nextItems \u001B[38;5;241m=\u001B[39m \u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msessions\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m key_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(embeddings\u001B[38;5;241m.\u001B[39mkeys())\n\u001B[0;32m     27\u001B[0m values_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(embeddings\u001B[38;5;241m.\u001B[39mvalues())\n",
      "Cell \u001B[1;32mIn[31], line 12\u001B[0m, in \u001B[0;36mtest\u001B[1;34m(loader, test_model, num_of_sessions, save_model_preds)\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m     10\u001B[0m         \u001B[38;5;66;03m# max(dim=1) returns values, indices tuple; only need indices\u001B[39;00m\n\u001B[0;32m     11\u001B[0m         preds \u001B[38;5;241m=\u001B[39m test_model(data)\n\u001B[1;32m---> 12\u001B[0m         preds_all[i\u001B[38;5;241m*\u001B[39margs\u001B[38;5;241m.\u001B[39mbatch_size:(i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m*\u001B[39margs\u001B[38;5;241m.\u001B[39mbatch_size,:] \u001B[38;5;241m=\u001B[39m preds\n\u001B[0;32m     13\u001B[0m         i \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m save_model_preds:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The expanded size of the tensor (76) must match the existing size (100) at non-singleton dimension 0.  Target sizes: [76, 100].  Tensor sizes: [100, 100]"
     ]
    }
   ],
   "source": [
    "#CHANGE MODEL NAMES ACCORDINGLY !!!!\n",
    "LOCALES = [\"ES\", \"FR\", \"IT\"]\n",
    "model_names = [\"ESmodel\", \"FRmodel\", \"ITmodel\"]\n",
    "\n",
    "for i in range(3):\n",
    "    locale = LOCALES[i]\n",
    "    model_name = model_names[i]\n",
    "\n",
    "    with open(\"../embeddings/{}-composed_embedding.pkl\".format(locale), 'rb') as f:\n",
    "        embeddings = pickle.load(f)\n",
    "\n",
    "    with open('../data/preprocessed-data/{}-sessions-test.pkl'.format(locale), 'rb') as f:\n",
    "        sessions = pickle.load(f)\n",
    "\n",
    "    test_dataset = GraphDataset('./', locale)\n",
    "    test_loader = pyg_data.DataLoader(test_dataset,\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  shuffle=False,\n",
    "                                  drop_last=True)\n",
    "\n",
    "    model = SRGNN(args.hidden_dim, args.num_items)\n",
    "    model.load_state_dict(torch.load(\"../model/{}\".format(model_name)))\n",
    "\n",
    "    nextItems = test(test_loader, model,len(sessions), True)\n",
    "\n",
    "    key_list = list(embeddings.keys())\n",
    "    values_list = list(embeddings.values())\n",
    "    stacked_embeddings = np.stack( values_list, axis=0)\n",
    "\n",
    "    stacked_embeddings = normalize(stacked_embeddings, axis=1, norm='l2')\n",
    "    nextItems = normalize(nextItems, axis=1, norm='l2')\n",
    "\n",
    "    sim = np.dot(nextItems, stacked_embeddings.T)\n",
    "    sortedSimilarity = np.argsort(sim, axis=1)\n",
    "    sortedSimilarity = sortedSimilarity[:, -100:]\n",
    "    recommendation_lists = []\n",
    "\n",
    "    for x in range(sortedSimilarity.shape[0]):\n",
    "        rec_sub_list = []\n",
    "        for y in range(sortedSimilarity.shape[1]):\n",
    "            rec_sub_list.append(key_list[sortedSimilarity[x, y]])\n",
    "        rec_sub_list.reverse()\n",
    "        recommendation_lists.append(rec_sub_list)\n",
    "\n",
    "    with open('./test-result/{}-recs.pkl'.format(locale), 'wb') as f:\n",
    "        pickle.dump(recommendation_lists, f)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
