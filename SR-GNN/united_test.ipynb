{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIjdpIpL6hog"
   },
   "source": [
    "# ‚öôÔ∏è Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CRxB48iDiAF_",
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:00.463172Z",
     "end_time": "2023-05-18T16:20:00.474174Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Python built-in libraries\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:00.620884Z",
     "end_time": "2023-05-18T16:20:00.627883Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import pip libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# Import torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "HGQ13SWwiHRl",
    "outputId": "d12c60ec-b6e4-4a7b-ea7d-42eb63711c87",
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:00.798570Z",
     "end_time": "2023-05-18T16:20:00.814942Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import PyG packages\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric.data as pyg_data\n",
    "from torch_geometric.typing import Adj, OptTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:00.974335Z",
     "end_time": "2023-05-18T16:20:00.987337Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYrSfhkh6nIc"
   },
   "source": [
    "# ‚öóÔ∏è Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AK8wBmby8SWt"
   },
   "source": [
    "# üì¶ Data Pipeline\n",
    "\n",
    "For data ingestion, we use PyTorch's `dataloader` and PyG's `Data` class. To learn more about the `Data` class, check out the documentation [here](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#module-torch_geometric.data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "82KWESLd-1gV",
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:01.705290Z",
     "end_time": "2023-05-18T16:20:01.708292Z"
    }
   },
   "outputs": [],
   "source": [
    "class GraphDataset(pyg_data.InMemoryDataset):\n",
    "    def __init__(self, root, file_name, transform=None, pre_transform=None):\n",
    "        self.file_name = file_name\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [f'{self.file_name}.txt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f'{self.file_name}.pt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        data_list = []\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        for session in sessions:\n",
    "            codes, uniques = pd.factorize(session)\n",
    "            senders, receivers = codes[:-1], codes[1:]\n",
    "\n",
    "            # Build Data instance\n",
    "            edge_index = torch.tensor([senders, receivers], dtype=torch.long)\n",
    "            #x = torch.tensor(uniques, dtype=torch.long)\n",
    "            x_new = torch.zeros((len(uniques), 100))\n",
    "\n",
    "            item_counter = 0\n",
    "            for item in uniques:\n",
    "                x_new[item_counter] = torch.tensor(embeddings[item])\n",
    "                item_counter += 1\n",
    "\n",
    "            #y = torch.tensor([y], dtype=torch.long)\n",
    "\n",
    "            data_list.append(pyg_data.Data(x=x_new, edge_index=edge_index))\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD9bwJaUCOge"
   },
   "source": [
    "# üîÆ Model Design\n",
    "\n",
    "Our gated session graph layer has two main parts: (1) message propagation to create an adjacency matrix (`self.propagate`) and (2) the GRU cell (`self.gru`). We will put these inside the `forward()` function.\n",
    "\n",
    "We only use one layer for our `GatedSessionGraphConv` implementation for simplicity. Also, our sessions have average length < 5, so we do not need a large receptive field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7K3HWrcwqp0Z",
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:02.233366Z",
     "end_time": "2023-05-18T16:20:02.239383Z"
    }
   },
   "outputs": [],
   "source": [
    "class GatedSessionGraphConv(pyg.nn.conv.MessagePassing):\n",
    "    def __init__(self, out_channels, aggr: str = 'add', **kwargs):\n",
    "        super().__init__(aggr=aggr, **kwargs)\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.gru = torch.nn.GRUCell(out_channels, out_channels, bias=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        m = self.propagate(edge_index, x=x, size=None)\n",
    "        x = self.gru(m, x)\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t, x):\n",
    "        return matmul(adj_t, x, reduce=self.aggr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TNsAHq8PCN3k",
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:02.578956Z",
     "end_time": "2023-05-18T16:20:02.609952Z"
    }
   },
   "outputs": [],
   "source": [
    "class SRGNN(nn.Module):\n",
    "    def __init__(self, hidden_size, n_items):\n",
    "        super(SRGNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_items = n_items\n",
    "\n",
    "        self.gated = GatedSessionGraphConv(self.hidden_size)\n",
    "\n",
    "        self.q = nn.Linear(self.hidden_size, 1)\n",
    "        self.W_1 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.W_2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.W_3 = nn.Linear(2 * self.hidden_size, self.hidden_size, bias=False)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch_map = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # (0)\n",
    "        #embedding = self.embedding(x).squeeze()\n",
    "\n",
    "        # (1)-(5)\n",
    "        v_i = self.gated(x, edge_index)\n",
    "\n",
    "        # Divide nodes by session\n",
    "        # For the detailed explanation of what is happening below, please refer\n",
    "        # to the Medium blog post.\n",
    "        sections = list(torch.bincount(batch_map).cpu())\n",
    "        v_i_split = torch.split(v_i, sections)\n",
    "\n",
    "        v_n, v_n_repeat = [], []\n",
    "        for session in v_i_split:\n",
    "            v_n.append(session[-1])\n",
    "            v_n_repeat.append(\n",
    "                session[-1].view(1, -1).repeat(session.shape[0], 1))\n",
    "        v_n, v_n_repeat = torch.stack(v_n), torch.cat(v_n_repeat, dim=0)\n",
    "\n",
    "        q1 = self.W_1(v_n_repeat)\n",
    "        q2 = self.W_2(v_i)\n",
    "\n",
    "        # (6)\n",
    "        alpha = self.q(F.sigmoid(q1 + q2))\n",
    "        s_g_split = torch.split(alpha * v_i, sections)\n",
    "\n",
    "        s_g = []\n",
    "        for session in s_g_split:\n",
    "            s_g_session = torch.sum(session, dim=0)\n",
    "            s_g.append(s_g_session)\n",
    "        s_g = torch.stack(s_g)\n",
    "\n",
    "        # (7)\n",
    "        s_l = v_n\n",
    "        s_h = self.W_3(torch.cat([s_l, s_g], dim=-1))\n",
    "        #print(\"SH: \")\n",
    "        #print(s_h.shape)\n",
    "        #print(s_h)\n",
    "\n",
    "\n",
    "        return s_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qd0wGgxOAIoJ"
   },
   "source": [
    "# üöÇ Model Training\n",
    "\n",
    "We can now start model training. The training pipeline code below was originally taken from the 2021 Fall CS224W Colab assignments and then modified to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Define the hyperparameters.\n",
    "# Code taken from 2021 Fall CS224W Colab assignments.\n",
    "args = {\n",
    "    'batch_size': 100,\n",
    "    'hidden_dim': 100,\n",
    "    'epochs': 1,\n",
    "    'l2_penalty': 0.00001,\n",
    "    'weight_decay': 0.1,\n",
    "    'step': 30,\n",
    "    'lr': 0.001,\n",
    "    'num_items': 466868}\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "\n",
    "args = objectview(args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:03.289715Z",
     "end_time": "2023-05-18T16:20:03.299714Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def test(loader, test_model,num_of_sessions, save_model_preds=False):\n",
    "    test_model.eval()\n",
    "\n",
    "    preds_all = torch.zeros(num_of_sessions, 100)\n",
    "    i = 0\n",
    "\n",
    "    for _, data in enumerate(tqdm(loader)):\n",
    "        data\n",
    "        with torch.no_grad():\n",
    "            # max(dim=1) returns values, indices tuple; only need indices\n",
    "            preds = test_model(data)\n",
    "            preds_all[i*args.batch_size:(i+1)*args.batch_size,:] = preds\n",
    "            i += 1\n",
    "\n",
    "    if save_model_preds:\n",
    "        np_preds = preds_all.cpu().detach().numpy()\n",
    "        return np_preds\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T16:20:54.731217Z",
     "end_time": "2023-05-18T16:20:54.743413Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dogat\\anaconda3\\envs\\bitirmesolution\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81/81 [00:03<00:00, 25.04it/s]\n",
      "Processing...\n",
      "C:\\Users\\dogat\\AppData\\Local\\Temp\\ipykernel_21652\\277422053.py:28: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  edge_index = torch.tensor([senders, receivers], dtype=torch.long)\n",
      "Done!\n",
      "C:\\Users\\dogat\\anaconda3\\envs\\bitirmesolution\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:03<00:00, 41.29it/s]\n",
      "Processing...\n",
      "Done!\n",
      "C:\\Users\\dogat\\anaconda3\\envs\\bitirmesolution\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 139/139 [00:03<00:00, 39.09it/s]\n"
     ]
    }
   ],
   "source": [
    "#CHANGE MODEL NAMES ACCORDINGLY !!!!\n",
    "LOCALES = [\"ES\", \"FR\", \"IT\"]\n",
    "\n",
    "with open(\"../SR-GNN/raw/united_composed_embedding.pkl\", 'rb') as f:\n",
    "        united_composed_embedding = pickle.load(f)\n",
    "\n",
    "for i in range(3):\n",
    "    locale = LOCALES[i]\n",
    "\n",
    "    with open(\"../embeddings/{}-composed_embedding.pkl\".format(locale), 'rb') as f:\n",
    "        embeddings = pickle.load(f)\n",
    "\n",
    "    for i in embeddings.keys():\n",
    "        embeddings[i] = united_composed_embedding[i]\n",
    "\n",
    "    with open('../data/preprocessed-data/{}-sessions-test.pkl'.format(locale), 'rb') as f:\n",
    "        sessions = pickle.load(f)\n",
    "\n",
    "    test_dataset = GraphDataset('./', locale)\n",
    "    test_loader = pyg_data.DataLoader(test_dataset,\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  shuffle=False,\n",
    "                                  drop_last=True)\n",
    "\n",
    "    model = SRGNN(args.hidden_dim, args.num_items)\n",
    "    model.load_state_dict(torch.load(\"../model/united-model\"))\n",
    "\n",
    "    nextItems = test(test_loader, model,len(sessions), True)\n",
    "\n",
    "    key_list = list(embeddings.keys())\n",
    "    values_list = list(embeddings.values())\n",
    "    stacked_embeddings = np.stack( values_list, axis=0)\n",
    "\n",
    "    stacked_embeddings = normalize(stacked_embeddings, axis=1, norm='l2')\n",
    "    nextItems = normalize(nextItems, axis=1, norm='l2')\n",
    "\n",
    "    sim = np.dot(nextItems, stacked_embeddings.T)\n",
    "    sortedSimilarity = np.argsort(sim, axis=1)\n",
    "    sortedSimilarity = sortedSimilarity[:, -100:]\n",
    "    recommendation_lists = []\n",
    "\n",
    "    for x in range(sortedSimilarity.shape[0]):\n",
    "        rec_sub_list = []\n",
    "        for y in range(sortedSimilarity.shape[1]):\n",
    "            rec_sub_list.append(key_list[sortedSimilarity[x, y]])\n",
    "        rec_sub_list.reverse()\n",
    "        recommendation_lists.append(rec_sub_list)\n",
    "\n",
    "    with open('./test-result/{}-recs.pkl'.format(locale), 'wb') as f:\n",
    "        pickle.dump(recommendation_lists, f)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
